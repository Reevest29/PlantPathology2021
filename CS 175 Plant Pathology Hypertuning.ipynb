{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiovascular-london",
   "metadata": {},
   "source": [
    "# Plant Pathology Hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-corporation",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acknowledged-slave",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/braedon/.local/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "# import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import timeit\n",
    "import copy\n",
    "\n",
    "from utils import utils, learner\n",
    "from utils import PlantPathologyDataset as dataset\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "import hyperopt as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 75\n",
    "NUM_VAL = 25\n",
    "users = ('braedon', 'thomas', 'shangyi')\n",
    "user = users[0]\n",
    "\n",
    "# Needs to be the full path because of raytune\n",
    "if user == users[1]:\n",
    "    csv_file='C:\\\\Users\\\\tjtom\\PycharmProjects\\PlantPathology2021\\\\train.csv'\n",
    "    root_dir='C:\\\\Users\\\\tjtom\\PycharmProjects\\PlantPathology2021\\\\train_images'\n",
    "    mappings_dir='C:\\\\Users\\\\tjtom\\PycharmProjects\\PlantPathology2021\\\\labelMappings.csv'\n",
    "elif user == users[0]:\n",
    "    csv_file='/home/braedon/skole/cs175/PlantPathology2021/train.csv'\n",
    "    root_dir='/home/braedon/skole/cs175/PlantPathology2021/train_images'\n",
    "    mappings_dir='/home/braedon/skole/cs175/PlantPathology2021/labelMappings.csv'\n",
    "\n",
    "plant_dataset = dataset.PlantPathologyDataset(csv_file=csv_file,\n",
    "                                              root_dir=root_dir,\n",
    "                                              mappings_dir=mappings_dir)\n",
    "train_data = DataLoader(plant_dataset, batch_size=10, sampler= learner.ChunkSampler(NUM_TRAIN, 0))\n",
    "validation_data = DataLoader(plant_dataset, batch_size=10, sampler=learner.ChunkSampler(NUM_VAL, NUM_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    resources_per_trial = {'gpu': 1}\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    dtype = torch.FloatTensor\n",
    "    resources_per_trial = {'cpu': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-accused",
   "metadata": {},
   "source": [
    "### Testing resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "textile-stylus",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    resnet50 = models.resnet50().cuda() # pretrained=True is pretrained on ImageNet\n",
    "else:\n",
    "    resnet50 = models.resnet50()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.RMSprop(resnet50.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "precious-raleigh",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting epoch 1 / 1\n",
      "2021-05-14 15:05:02,489\tWARNING worker.py:1115 -- A worker died or was killed while executing task fffffffffffffffff9492f7d4957197356fc469c01000000.\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 2.4781\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 2.3116\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 9 / 25 correct (36.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 1.9655\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 6 / 25 correct (24.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 2.0939\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 6 / 25 correct (24.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 2.0682\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 7 / 25 correct (28.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 1.7083\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 1.4737\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 1.3888\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 7 / 25 correct (28.00)\n",
      "4min ± 1.06 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.cuda.synchronize()\n",
    "learner.train(resnet50, train_data, loss_fn, optimizer, dtype, print_every=5)\n",
    "learner.check_accuracy(resnet50, validation_data, dtype)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 11.4072\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 5.4207\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 1 / 25 correct (4.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 8.1493\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 10.7226\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 1 / 25 correct (4.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 3.1798\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 1 / 25 correct (4.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 8.8450\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 9.8844\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 0 / 25 correct (0.00)\n",
      "Starting epoch 1 / 1\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3, 11,  9,  9,  0,  3,  6,  3,  0,  3])\n",
      "torch.Size([10, 3, 400, 267]) tensor([0, 9, 3, 9, 1, 9, 9, 9, 3, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([4, 6, 9, 9, 3, 9, 6, 3, 0, 9])\n",
      "torch.Size([10, 3, 400, 267]) tensor([3, 1, 9, 6, 9, 3, 3, 0, 0, 4])\n",
      "torch.Size([10, 3, 400, 267]) tensor([ 3,  9, 11,  1,  4,  9,  3,  1,  1,  4])\n",
      "t = 5, loss = 10.6991\n",
      "torch.Size([10, 3, 400, 267]) tensor([10,  9,  3,  9,  6,  1,  1,  0,  3,  1])\n",
      "torch.Size([10, 3, 400, 267]) tensor([9, 9, 2, 3, 1, 9, 1, 6, 4, 9])\n",
      "torch.Size([5, 3, 400, 267]) tensor([9, 6, 9, 0, 9])\n",
      "Checking accuracy on validation set\n",
      "Got 8 / 25 correct (32.00)\n",
      "4min 17s ± 4.87 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dtype = torch.FloatTensor\n",
    "resnet50 = models.resnet50()\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.RMSprop(resnet50.parameters(), lr=1e-3)\n",
    "learner.train(resnet50, train_data, loss_fn, optimizer, dtype, print_every=5)\n",
    "learner.check_accuracy(resnet50, validation_data, dtype)"
   ]
  },
  {
   "source": [
    "### Hypertuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is called by raytune in the hyperparameter tuning. \n",
    "def train_resnet(config):\n",
    "    dtype = config['dtype']\n",
    "    model = models.resnet50().type(dtype)\n",
    "    # train_loader, test_loader = get_data_loaders()\n",
    "    loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "    # optimizer = optim.SGD(\n",
    "    #     model.parameters(), lr=config[\"lr\"])#, momentum=config[\"momentum\"])\n",
    "    optimizer = optim.RMSprop(model.parameters(), config['lr'], config['alpha'], config['eps'], config['weight_decay'], config['momentum'], config['centered'])\n",
    "    for i in range(10):\n",
    "        learner.train(model, train_data, loss_fn, optimizer, dtype, print_every=5)\n",
    "        acc = learner.check_accuracy(model, validation_data, dtype)\n",
    "        tune.report(mean_accuracy=acc)\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'scheduler' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0f4892a4e39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_resnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msearch_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scheduler' is not defined"
     ]
    }
   ],
   "source": [
    "# Add hyperparameters here for additional tuning\n",
    "# change their values to adjust the range and selection mechanism (uniform between two points, uniform from given options, iterate through all given options, etc.)\n",
    "search_space = {\n",
    "    'dtype': dtype, # don't change this one, not a hyperparameter\n",
    "    'lr': tune.loguniform(0.001, 10),\n",
    "    'alpha': tune.uniform(.1, 1.5),\n",
    "    'eps': tune.uniform(1e-20, 1e-3),\n",
    "    'weight_decay': tune.uniform(1e-20, 1),\n",
    "    'momentum': tune.uniform(1e-20, 1),\n",
    "    'centered': tune.choice((True, False))\n",
    "}\n",
    "\n",
    "num_samples = -1 # -1 is infinite\n",
    "time_budget_s = 2*60*60 # max number of seconds to run\n",
    "hyperopt = HyperOptSearch()\n",
    "scheduler = ASHAScheduler(grace_period=1)\n",
    "\n",
    "# This is what does the hyperparameter tuning. Right now, it's set to call the train_resnet function, and it works toward maximizing the mean_accuracy. It can also minimize loss.\n",
    "analysis = tune.run(\n",
    "    train_resnet,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=scheduler,\n",
    "    config=search_space,\n",
    "    search_alg=hyperopt,\n",
    "    resources_per_trial=resources_per_trial,\n",
    "    metric=\"mean_accuracy\",\n",
    "    mode=\"max\",\n",
    "    time_budget_s=time_budget_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dtype': torch.cuda.FloatTensor,\n",
       " 'lr': 0.012569618368549761,\n",
       " 'alpha': 0.8508139209606547,\n",
       " 'eps': 0.0004857270046904545,\n",
       " 'weight_decay': 0.6167323331742625,\n",
       " 'momentum': 0.605770928445852,\n",
       " 'centered': True}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "analysis.get_best_config('mean_accuracy', 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(analysis, open('analysis.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do (analysis)...\n",
    "\n",
    "# print(\"Best config: \", analysis.get_best_config(\n",
    "#     metric=\"mean_loss\", mode=\"min\"))\n",
    "\n",
    "# # Get a dataframe for analyzing trial results.\n",
    "# df = analysis.results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}